#####
###
@@@@# FaceDetect
1111
2222
3333
4444
5555
6666

Claro, aquí tienes un texto claro y motivador sobre **aprender a programar**, ideal para un ensayo corto, una publicación o presentación:

---

### **Aprender a Programar: Mucho Más que Escribir Código**

Aprender a programar es una de las habilidades más valiosas del siglo XXI. No se trata solo de escribir líneas de código en una pantalla, sino de desarrollar la capacidad de resolver problemas, pensar lógicamente y construir herramientas que impacten el mundo real.

Programar es como aprender un nuevo lenguaje, pero en lugar de comunicarte con personas, te comunicas con computadoras. A través de lenguajes como Python, JavaScript o C++, das instrucciones precisas que las máquinas ejecutan al pie de la letra. Esto requiere atención al detalle, paciencia y mucha práctica.

El camino para convertirse en programador puede parecer desafiante al principio. Es común sentirse frustrado cuando algo no funciona o no se entiende un concepto técnico. Pero con perseverancia, cada error se convierte en una oportunidad de aprendizaje. Cada pequeño logro —como hacer que un botón funcione o que un programa calcule correctamente— alimenta la confianza y la motivación para seguir.

Además, programar te abre puertas a un mundo de creatividad. Desde desarrollar aplicaciones móviles, videojuegos, sitios web, hasta trabajar con inteligencia artificial o análisis de datos, las posibilidades son prácticamente infinitas.

Lo más importante es empezar, aunque sea con lo más básico. Hoy en día, hay muchos recursos gratuitos y accesibles para aprender, desde plataformas en línea hasta comunidades de apoyo. Con dedicación constante, cualquiera puede aprender a programar y convertir esa habilidad en una herramienta poderosa para su vida personal y profesional.

---

¿Quieres que lo adapte a un público específico, como niños, estudiantes, adultos, o para una presentación?


**Training parameters**
Learning is very interesting
The network was trained with TensorFlow's AdamOptimzer 
    
    lrate: 1e-4
    epsilon: 1e-16
    mini-batch size: 100
    number of epochs: 8

The validation accuracy was 98.762% and the final accuracy on the test set was 98.554%.

**Dataset**

Positive samples (images of faces) for the classification were taken from 2 sources:

    1. Cropped labelled faces in the wild (http://conradsanderson.id.au/lfwcrop/)
    2. MIT CBCL face recognition database (http://cbcl.mit.edu/software-datasets/heisele/facerecognition-database.html)

The horizontal mirror images of these images were included in the dataset.

Negative samples (non-faces) were taken from 4 sources:

    1. Fifteen scene categories (http://www-cvr.ai.uiuc.edu/ponce_grp/data/)
    2. Texture database (http://www-cvr.ai.uiuc.edu/ponce_grp/data/)
    3. Caltech cars (Rear) background dataset (http://www.robots.ox.ac.uk/~vgg/data3.html)
    4. Caltech houses dataset (http://www.robots.ox.ac.uk/~vgg/data3.html)
    
Random snapshots from these images were generated by taking sub-images of a random lengths at random positions in the images. These snapshots were mixed in the dataset along with the complete images.

The final dataset consists of the 32,000 images from each class (positive and negative). Training, validation and test sets were generated from this with a 0.6 split for training, 0.2 for validation and 0.2 for test. Each of these sets have 50% positive and 50% negative samples.

**Localization**

The module uses a simple sliding window localizer. The input image is reshaped to (300,300). Square windows of side lengths 40,50... 100 are slid along the image. Each sub image seen through the window is reshaped to (32,32) and fed to the network. If the sub image is a face with a minimum confidence of 0.99, the window is marked in the mask. After running all different sized windows on the image, the final mask is blurred with a 50x50 Gaussian filter and binarized. This final binarized mask is used to extract only the faces from the image. The localizer returns two images: an image with only the faces and the raw mask (before blurring and binarization).

**Demo**

The repo includes a pre-trained model: face_model. This can directly be used for localization. Sample usage of this model with FaceDetect.py can be seen in demo.py. Running the demo should display the result of running the localizer on demo.jpg.
Demos with other images can be seen here: https://youtu.be/N4GIGVnyNBo 

Output of demo.py:
![Alt text](demo_result.png?raw=true)
BYE??
